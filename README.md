# ğŸ§  SCIRAG â€” Assistant conversationnel intelligent avec RAG et gestion de notes

**SCIRAG** est une application locale (ou hybride) de chat intelligent basÃ©e sur les LLMs (Claude, GPT, etc.), enrichie par la recherche de documents via RAG (Retrieval-Augmented Generation) et l'intÃ©gration de notes personnelles activables.

---

## ğŸš€ FonctionnalitÃ©s principales

- ğŸ” Conversations persistantes et organisÃ©es  
- ğŸ“‚ IntÃ©gration de documents PDF dans des corpus RAG  
- ğŸ—’ï¸ Ajout de notes personnelles utilisables comme sources RAG  
- ğŸ§  Prise en charge de modÃ¨les LLM :
  - Locaux via [LM Studio](https://lmstudio.ai/)
  - API (Claude, OpenAI, Cohere, etc.)
- ğŸ§¬ Embedding et recherche vectorielle avec stockage local (ChromaDB)
- ğŸ§ª Interface en ligne de commande (CLI) ou frontend web (optionnel)

---

## ğŸ§± Stack technique

| Composant         | Technologie               |
|-------------------|---------------------------|
| Backend API       | FastAPI                   |
| Base de donnÃ©es   | PostgreSQL ou SQLite      |
| Vector Store      | ChromaDB                  |
| Embeddings        | OpenAI / modÃ¨le local     |
| ModÃ¨les LLM       | LM Studio / API externes  |
| Frontend (option) | Next.js / React           |

---

## ğŸ“ Structure du projet

```bash
SCIRAG/
/backend
â”œâ”€â”€ api/
â”‚   â””â”€â”€ routes/                # Endpoints REST
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ loader.py              # Lecture PDF
â”‚   â”œâ”€â”€ chunker.py             # Split texte
â”‚   â”œâ”€â”€ embedder.py            # Embeddings
â”‚   â””â”€â”€ store.py               # CHROMADB index
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ router.py
â”‚   â””â”€â”€ providers/
â”‚       â”œâ”€â”€ anthropic.py
â”‚       â”œâ”€â”€ openai.py
â”‚       â””â”€â”€ local.py
â”œâ”€â”€ conversations/
â”‚   â”œâ”€â”€ controller.py
â”‚   â””â”€â”€ context_manager.py

/frontend
â”œâ”€â”€ gradio_app.py              # Point d'entrÃ©e principal
â”œâ”€â”€ pages/                     # Pages principales de l'application
â”‚   â”œâ”€â”€ chat_interface.py      # Interface de conversation
â”‚   â”œâ”€â”€ rag_manager.py         # Gestion des corpus RAG
â”‚   â”œâ”€â”€ llm_config.py          # Configuration des modÃ¨les LLM
â”‚   â””â”€â”€ notes_manager.py       # Gestion des notes
â”œâ”€â”€ components/                # Composants rÃ©utilisables
â”‚   â”œâ”€â”€ message_block.py       # Affichage des messages dans le chat
â”‚   â”œâ”€â”€ source_viewer.py       # Visualisation des sources RAG
â”‚   â”œâ”€â”€ model_selector.py      # SÃ©lecteur de modÃ¨le LLM
â”‚   â””â”€â”€ context_selector.py    # Activation des sources RAG/notes
â”œâ”€â”€ services/                  # Services et utilitaires
â”‚   â”œâ”€â”€ api_client.py          # Client pour l'API backend
â”‚   â”œâ”€â”€ state_manager.py       # Gestion de l'Ã©tat de l'application
â”‚   â””â”€â”€ utils.py               # Fonctions utilitaires
â””â”€â”€ assets/                    # Ressources statiques
    â”œâ”€â”€ styles.css             # Styles CSS personnalisÃ©s
    â””â”€â”€ logo.png               # Logo de l'application
```

---

## âš™ï¸ Installation

### 1. PrÃ©-requis

- Python 3.10+
- Node.js (si frontend)
- PostgreSQL ou SQLite
- [LM Studio](https://lmstudio.ai/) pour les modÃ¨les locaux
- (Facultatif) ClÃ© API : OpenAI, Claude, Cohereâ€¦

### 2. Cloner et installer

```bash
git clone https://github.com/votre-org/SCIRAG.git
cd SCIRAG
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
3. Configuration
CrÃ©ez un fichier .env Ã  la racine :
DATABASE_URL=postgresql://user:pass@localhost:5432/SCIRAG
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=...
LM_STUDIO_URL=http://localhost:1234/v1
________________________________________
â–¶ï¸ Lancement
uvicorn api.main:app --reload
â€¢	AccÃ©dez Ã  http://localhost:8000/docs pour tester l'API via Swagger.
________________________________________
ğŸ§  Utilisation
â€¢	CrÃ©ez une conversation
â€¢	Chargez un dossier PDF â†’ crÃ©ation RAG
â€¢	CrÃ©ez et activez des notes dans les conversations
â€¢	SÃ©lectionnez un modÃ¨le LLM (local ou distant)
â€¢	Envoyez un prompt â†’ LLM rÃ©pond avec contexte enrichi
________________________________________
ğŸ§ª Tests
pytest tests/
________________________________________
ğŸ“š Documentation
â€¢	ğŸ“„ Documentation Technique
â€¢	ğŸ“„ SpÃ©cifications Fonctionnelles
â€¢	ğŸ“„ Guide Installation
________________________________________
ğŸ—“ï¸ TODO
â€¢	 Interface CLI interactive
â€¢	 Import/export de conversations
â€¢	 Auth multi-utilisateur
â€¢	 UI React / Next.js
________________________________________
ğŸ‘¤ Auteur
Projet par Erwan Tinturier
Chef de projet & Prompt Engineer
________________________________________
âš–ï¸ Licence
MIT
